---
title: "Midterm Code Section"
author: "STUDENT NAME"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Instructions

You will need to complete the portion of the exam before starting the second portion. You will use your answers on this exam to complete the second half. Only knitted files will be graded! Make sure your complete this portion of the exam on your own. Use your notes and class examples to get started with the code. 

# Abstract

Eventual memory performance is predicted more accurately when a person's judgment of learning (JOL) is delayed until shortly after studying an item than when made immediately after studying the item. According to the transfer-appropriate-monitoring hypothesis, this delayed- JOL effect arises because of the contextual similarity between the cue for the JOL and the cue for the memory test. In a paired-associate learning experiment, delayed JOLs were cued by the stimulus alone or by the stimulus-response pair, and the eventual test was associative recognition of stimulus-response pairs. Recognition of stimulus-response pairs was predicted more accurately when JOLs had been cued by the stimulus alone than when they had been cued by the stimulus-response pair, even though the latter was more similar than the former to the cue for the recognition test. Implications of these results, especially the lack of support for the class of theories emphasizing transfer-appropriate monitoring, are discussed for theories of the accuracy of JOLs.

# Method

In these experiments, participants are given English word pairs to learn (i.e. dog-table). They are asked after each word pair: â€œhow confident are you that in about ten minutes from now you will be able to recognize the second of the item when prompted with the first? (0 = definitely won't recognize, 20 = 20% sure, 40 ..., 60 ..., 80 ..., 100 = definitely will recognize). These ratings (JOLs) were given either right after the word pair was presented or after the entire block of word pairs were presented. These ratings were prompted with either just the cue word (i.e. dog, the first word of each pair) or both the words (stimulus-response pairing). After all word-pairs were studied, a 10-minute break was given. Participants were then measured by marking which word-pairings they recognized (0 = not studied, 20 = 20 % sure studied, 40 ..., 60 ..., 80 ..., 100 = definitely studied). You can assume the ratings are continuous.  

# Dataset:

- JOL group: if they rated their confidence immediately or at the end of each block for how well they would remember the word-pairs.
- Type cue: what type of cue they were using to rate their confidence, either the word-pair or the cue word only.
- Confidence: their average rated confidence to remember word pairs across trial blocks.
- Recognition: their average memory for words across trial blocks.
  
In this section, the data will be loaded for you from the package. You will change the id = 123456 to your HU id number. This number will generate your data for you in the same time each way, so if you rerun this analysis, you will get the same numbers each time.   

```{r starting}
library(learnSTATS)
midterm <- midterm_data(idnum = 123456) #CHANGE ME
head(midterm)
```

# Data screening:

## Accuracy:
    
- Include output and indicate how the data are not accurate.
- Include output to show how you fixed the accuracy errors, and describe what you did.

```{r accuracy}

```

## Missing data:

- Using the 5% rule, exclude all rows that have missing data.
- Create separate datasets for your continuous measures and categorical measures (because everyone can have slightly different, estimate all continuous columns regardless of their missingness for columns). 
- Estimate the missing data for your continuous measures.
- Combine your categorical columns back to your newly estimated continuous columns. 
    
```{r missing}

```

## Outliers:

- Calculate your Mahalanobis distance scores. 
- Include a summary of your mahal scores that are greater than the cutoff.
- How many outliers did you have? 
- Exclude all outliers. 

```{r outliers}

```

# Assumptions:

## Additivity: 

- Include a `corrplot()` of your continuous measures. 
    
```{r additivity}

```

## Linearity: 

- Include a picture that shows how you might assess multivariate linearity.

```{r linearity}

```

## Normality: 

- Include a picture that shows how you might assess multivariate normality.

```{r normality}

```

## Homogeneity/Homoscedasticity:

- Include a picture that shows how you might assess multivariate homogeneity.

```{r homog-s}

```

# Data exploration:

Create and save average scores for confidence and recognition across trial blocks (two separate columns). Use the following: `apply(dataset[ , column #s for confidence or recognition], 1, mean)`. You will use these average scores for the rest of the test. 

```{r avg-scores}

```

Create histograms of the confidence and recognition average scores (you can use hist or ggplot2). These charts do not have to be pretty. 

- Do these frequency distributions appear normal?

```{r histogram}

```

Print out the means, standard deviations, and length for each condition (JOL-Group and Type Cue combined together) in the study for average recognition only. 

```{r descriptives}

```

Use MOTE to calculate the effect size for the difference between recognition scores for the following comparisons:

- Immediate JOL versus Delay JOL for cue only.
- Immediate JOL versus Delay JOL for stimulus pairs.
- What are the sizes of these effects? 

```{r MOTE}

```

# Charts:

On all of these questions, be sure to include a coherent label for the X and Y axes. You should change them to be "professional looking" (i.e. Proper Case, explain the variable listed, and could be printed in a journal). The following will be assessed:

- Is it readable?
- Is X-axis labeled appropriately?
- Is Y-axis labeled appropriately?
- Is it the right graph?
- Do the labels look appropriate?
- Are there error bars when appropriate?

Make a bar chart with two independent variables: JOL group, type cue, average recognition. Use `na.omit(dataset)` to exclude any missing data. 

```{r two-iv-bar}

```

Make a repeated measures bar chart: Type of rating (average confidence, average recognition), rating. Hint: create a smaller dataset of just these variables first.

```{r rm-bar}

```

Make a scatterplot of confidence 1 (`conf1`) and recognition 1 (`rec1`) to indicate how their first ratings are related. 

```{r scatter-line}

```